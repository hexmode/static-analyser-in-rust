* Writing a Static Analyser in Rust
  :PROPERTIES:
  :CUSTOM_ID: writing-a-static-analyser-in-rust
  :END:
Original introduction from [[https://github.com/Michael-F-Bryan/static-analyser-in-rust/blob/master/src/lib.md][Micheal Bryan]]:
#+begin_quote
  To try out the concept of [[https://en.wikipedia.org/wiki/Literate_programming][/Literate Programming/]] (using the awesome [[https://github.com/pnkfelix/tango][tango]] crate), I'm going to write a small static analyser for a basic Programming language. Because it's so much more interesting to use a programming language available in the wild, compared to some contrived example, we're going to analyse Delphi (a Pascal variant).
#+end_quote

** What makes this project different
Since Micheal put the project on github, I discovered it just as I was looking for a way to strengthen my Rust and shore up some things I had learned in comp sci a long time ago.  The focus of the project, the focus on literate programming, and the chance to use (only hopefully as of this writing) the CI and “Pages” infrastructure on Gitlab and Github simultaneously, piqued my interest.

The original project targeted Delphi and used tango.  I've changed everything to use [[https://orgmode.org/][Emacs' Org Mode]], strengthened the Makefile and hope to target [[https://www.freepascal.org/][Free Pascal]] instead of Delphi.

#+begin_quote
  *Note:* The API docs for this crate should be placed alongside the book. You can access then [[../doc/static_analyser/index.html][here]] (you'll need to use =cargo doc --open= if viewing locally).
#+end_quote

** Hello World for Pascal

Here's your basic Hello World:

#+begin_src pascal
  program HelloWorld;
  begin
    writeln('Hello, World!');
  end.
#+end_src

This, and any other Pascal programs used for development are in my [[https://gitlab.com/hexmode1/pascal-progs][Pascal programs repository]].

If you have the pascal repository checked out, you should just be able to type =make hello= in the repository and then =./hello= to run the program.

** Getting started

First up, lets add some top-level docs and import some crates we're going to need:

#+begin_src rust
//! A parser and static analysis library for exploring Pascal code.
//!
//! This is written using a *Literate Programming* style, so you may find it
//! easier to inspect the [rendered version] instead.
//!
//! [rendered version]: https://hexmode.github.io/static-analyser-in-rust/

#![deny(missing_docs)]

#[cfg(test)]
#[macro_use]
extern crate pretty_assertions;
#[macro_use]
extern crate error_chain;
extern crate serde;
#[macro_use]
extern crate serde_derive;
#+end_src

There are several steps you need to perform to do static analysis, first is [[https://en.wikipedia.org/wiki/Lexical_analysis][lexical analysis]] or “tokenization”. This stage turns the characters in the raw source code into =Tokens= like =if=, =begin=, integer literals and operators.  We handle this in the [[./lex.org][lex module]].

#+begin_src rust
pub mod lex;
#+end_src

Next we do the syntactic analysis or [[https://en.wikipedia.org/wiki/Parsing][parsing]] to convert our stream of tokens into an [[https://en.wikipedia.org/wiki/Abstract_syntax_tree][Abstract Syntax Tree (AST)]]. This is a data structure that represents the program as it exists on disk. Check [[./parse/ast.org][ast]] for this.

Once we have an AST, we can perform our static analysis. For example, if you want to make sure people don't accidentally divide by zero it's just a case of looking for all division nodes and checking that the right hand isn't a numeric literal representing zero (e.g. =0= or =0.0=).

Another useful lint which can be applied at this level is [[https://en.wikipedia.org/wiki/Cyclomatic_complexity][cyclomatic complexity]], i.e. how “complex” a function/procedure is. This is normally just a case of walking the body of a function and counting the number of branches, loops, and =try/catch= blocks encountered.

#+begin_src rust
#[macro_use]
pub mod parse;
#+end_src

The third step is type checking and generating a High level [[https://en.wikipedia.org/wiki/Intermediate_representation][Intermediate Representation]] (HIR), often referred to as “[[./lowering.org][lowering]]”—the process of converting from a high level representation to a lower one. (For a more thorough explanation of intermediate representations, see Fred Chow's paper: [[https://dl.acm.org/doi/pdf/10.1145/2542661.2544374][Intermediate Representation: The increasing significance of intermediate representations in compilers]].)

While the AST is very flexible and useful, it works at the language syntax level and completely misses the /semantics/ of a language. This means an expression like ='foo' + 42= or dereferencing a float is a perfectly valid AST node.

To perform some of the more advanced analyses we'll need to have access to the full context surrounding an expression to determine if it is valid. This typically involves figuring out the type for each variable and expression, as well as resolving imports and stitching multiple unit files into one cohesive data structure.

#+begin_src rust
pub mod lowering;
#+end_src

Now we've /finally/ resolved all imports and types we're /guaranteed/ to have a syntactically and semantically valid program. This doesn't mean it's correct though! At this stage we can create passes which employ the full strength of the compiler/static analyser to check the /logic/ of our program. This lets us do [[./analysis.org][analysis]].

#+begin_src rust
pub mod analysis;
#+end_src

We also need to handle internal [[./errors.org][errors]]. To keep things clean lets put that in its own module too.

#+begin_src rust
pub mod errors;
#+end_src

Another very important thing to have is a mapping, or [[./codemap.org][codemap]], which lets you talk about a logical chunk of code (i.e. /this/ function body or /that/ string literal) and retrieve the corresponding source code. This will be crucial for the later steps where we want to indicate where an error occurred to the user.

#+begin_src rust
pub mod codemap;
#+end_src

Finally, there's the [[./driver.org][driver]]. It's in charge of the show and is usually the thing you'll want to invoke or hook into to tweak the analysis process.

#+begin_src rust
mod driver;
pub use driver::Driver;
#+end_src

** A Note on Project Design
   :PROPERTIES:
   :CUSTOM_ID: a-note-on-project-design
   :END:
A lot of the time, if you need to write a parser you'll want to use some sort of parser combinator or generator library. This greatly decreases the effort and time required, but you often trade that off with poor error handling and error messages. Because we're writing a tool for analysing your code, it stands to reason that if the user passes in dodgy code, we can detect this (without crashing) and emit a *useful* error message. All of this means that we'll want to write the lexing and parsing stuff by hand instead of deferring to another tool.

If you are following along at home, click through to one of the sections to learn about it in more detail.
